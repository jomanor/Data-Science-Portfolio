{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8UnVX9DfsD8"
      },
      "source": [
        "\n",
        "## CLASIFICACIÓN DEL RIESGO DE ABANDONO DE LOS CLIENTES DE UN BANCO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c20mLyX0fsEE"
      },
      "source": [
        "El conjunto de datos con el que vamos a trabajar ahora contiene información sobre los usuarios de un banco. Queremos predecir si los clientes van a dejar de usar los servicios de dicho banco o no. El conjunto de datos consta de 10000 observaciones y 14 variables.\n",
        "\n",
        "La siguiente figura indica cómo cargar el conjunto de Datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm2vcrQ8fsEI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKcqWoKqfsEM"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('C:/Users/Usuario/Downloads\\Churn_Modelling.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Wo9cXjfsEO",
        "outputId": "ded2906e-4d72-4694-a7bb-dea3b845384b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPiUJk_wfsEP"
      },
      "source": [
        "Creamos una matriz con las variables de entrada y otra matriz con la variable de salida (objetivo, columna 14). Excluiremos la columna 1 y 2 que son ‘row_number’ y ‘customerid’ ya que no nos aportan información útil para el análisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emmBpDYofsER"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:,3:13].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CBhxKN0fsES",
        "outputId": "7fef31c3-a250-4773-8bc2-48fbe1995f51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', 41, 1, 83807.86, 1, 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', 42, 8, 159660.8, 3, 1, 0, 113931.57],\n",
              "       [699, 'France', 'Female', 39, 1, 0.0, 2, 0, 0, 93826.63]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hk-69xSfsEU"
      },
      "outputs": [],
      "source": [
        "y = dataset.iloc[:,13].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15dheHCnfsEW"
      },
      "source": [
        "Vamos a hacer el análisis más sencillo si codificamos las variables no numéricas. Country contiene los valores: ’France, Spain, Germany’ y Gender: ‘Male, Female’. La manera de codificarlo será convertir estas palabras a valores numéricos. Para esto usaremos la función LabelEncoder, de la librería ‘ScikitLearn’, que al darle una cadena de texto nos devuelve valores entre 0 y n_clases-1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuR4RlrSfsEX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr9PRH1AfsEZ",
        "outputId": "0cbb038c-4d12-44ff-c23d-455e3f85a250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bysEoJDqfsEa"
      },
      "source": [
        "Observamos que Country ahora toma valores del 0 al 2 mientras que male y female fueron reemplazados por 0 y 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSz4Cid9fsEb"
      },
      "source": [
        "Usaremos la función train_test_split de la librería ScikitLearn para dividir nuestros datos.\n",
        "\n",
        "Usaremos 80% para entrenar el modelo y 20% para validarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZUOUdn0fsEc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXqRIOEhfsEd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu3wQB6NfsEe",
        "outputId": "6addeef1-bbe4-455c-851b-975024fd2576"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[550, 0, 1, ..., 1, 1, 184221.11],\n",
              "        [554, 1, 0, ..., 0, 1, 140003.0],\n",
              "        [651, 0, 1, ..., 1, 0, 13898.31],\n",
              "        ...,\n",
              "        [745, 0, 1, ..., 1, 0, 146041.45],\n",
              "        [554, 0, 0, ..., 1, 0, 32824.15],\n",
              "        [850, 0, 1, ..., 1, 0, 31288.77]], dtype=object),\n",
              " array([[544, 2, 1, ..., 1, 1, 80676.83],\n",
              "        [635, 1, 0, ..., 1, 1, 156791.36],\n",
              "        [680, 0, 1, ..., 1, 0, 164119.35],\n",
              "        ...,\n",
              "        [687, 2, 0, ..., 1, 1, 154767.34],\n",
              "        [691, 1, 0, ..., 1, 0, 107665.02],\n",
              "        [609, 1, 1, ..., 0, 1, 171430.16]], dtype=object),\n",
              " array([0, 1, 0, ..., 0, 0, 0], dtype=int64),\n",
              " array([0, 0, 0, ..., 0, 0, 0], dtype=int64))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh5pYsp9fsEg"
      },
      "source": [
        "Si observamos los datos detenidamente podemos apreciar que hay variables cuyos valores pueden\n",
        "ser muy variados, desde muy altos a muy pequeños por esta razón escalaremos los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGzJ9hH0fsEh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuIcWDomfsEh"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOySz-IEfsEi"
      },
      "outputs": [],
      "source": [
        "X_train = sc.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAKMh-JBfsEi"
      },
      "outputs": [],
      "source": [
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn_ctZqGfsEj",
        "outputId": "a4937399-d364-44d5-dd53-143f0ba01aab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-1.03625368, -0.90067582,  0.91255717, ...,  0.64959174,\n",
              "          0.970194  ,  1.46976231],\n",
              "        [-0.99501955,  0.30565376, -1.09582175, ..., -1.53942844,\n",
              "          0.970194  ,  0.70016316],\n",
              "        [ 0.00490815, -0.90067582,  0.91255717, ...,  0.64959174,\n",
              "         -1.0307217 , -1.49464035],\n",
              "        ...,\n",
              "        [ 0.97391025, -0.90067582,  0.91255717, ...,  0.64959174,\n",
              "         -1.0307217 ,  0.80526005],\n",
              "        [-0.99501955, -0.90067582, -1.09582175, ...,  0.64959174,\n",
              "         -1.0307217 , -1.1652434 ],\n",
              "        [ 2.05630622, -0.90067582,  0.91255717, ...,  0.64959174,\n",
              "         -1.0307217 , -1.1919661 ]]),\n",
              " array([[-1.09810488,  1.51198333,  0.91255717, ...,  0.64959174,\n",
              "          0.970194  , -0.33238596],\n",
              "        [-0.16002838,  0.30565376, -1.09582175, ...,  0.64959174,\n",
              "          0.970194  ,  0.99235809],\n",
              "        [ 0.30385561, -0.90067582,  0.91255717, ...,  0.64959174,\n",
              "         -1.0307217 ,  1.11989893],\n",
              "        ...,\n",
              "        [ 0.37601534,  1.51198333, -1.09582175, ...,  0.64959174,\n",
              "          0.970194  ,  0.9571308 ],\n",
              "        [ 0.41724947,  0.30565376, -1.09582175, ...,  0.64959174,\n",
              "         -1.0307217 ,  0.13733308],\n",
              "        [-0.42805024,  0.30565376,  0.91255717, ..., -1.53942844,\n",
              "          0.970194  ,  1.24714076]]),\n",
              " array([0, 1, 0, ..., 0, 0, 0], dtype=int64),\n",
              " array([0, 0, 0, ..., 0, 0, 0], dtype=int64))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnvZ-4s7fsEk"
      },
      "source": [
        "Una vez escalados los datos, pasamos a construir la red neuronal. Importamos Keras, usamos el módulo Sequential para inicializar la red y el modelo Dense para añadir capas ocultas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvv_TmWOfsEl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP3iZ7KsfsEm"
      },
      "source": [
        "Inicializamos la red con Sequential()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd823BP4fsEn"
      },
      "outputs": [],
      "source": [
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GiGupgzfsEn"
      },
      "source": [
        "Añadimos las capas usando la función Dense. Indicamos el número de nodos que queremos añadir con output_dim, Init es la inicialización del descenso de gradiente estocástico. Los pesos iniciales serán una variable aleatoria uniforme. Input_dim sólo es necesaria en la primera capa para que el modelo sepa la cantidad de variables que va a recibir, en nuestro caso 11. A partir de aquí las siguientes capas heredarán esta cualidad de la primera capa. La función de activación que utilizaremos será relu en las dos primeras capas (cuanto más cerca tenga su valor a 1, la neurona estará más activada y tendrá más interacción) y en la capa final hemos utilizado la función sigmoide ya que nuestro objetivo es clasificar.\n",
        "\n",
        "Una vez que tenemos la configuración específica de la red, la siguiente tarea es compilarla, para eso utilizamos la función Compile. El primer argumento de esta función es Optimizer que indica el método para entrenar los pesos. Adam es un algoritmo que se basa en el cálculo del descenso del Gradiente Estocástico. El segundo parámetro es loss, este usará la función ‘binary_crossentropy’ para clasificar en 2 categorías. Si tuviéramos más categorías utilizaríamos la función ‘categorical_crossentropy’. Para saber la bondad de nuestra red neuronal utilizaremos la métrica accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMB4u92nfsEo"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(6, activation = 'relu', input_shape = (10,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0jeKQMqfsEp"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(6, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTwizhu5fsEq"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEi0rz6qfsEr"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCODDBaOfsEs"
      },
      "source": [
        "Usaremos la función fit para ajustar los pesos de la red. Batch_size para especificar el número de observaciones que necesita entrenar antes de actualizar los pesos. Epoch nos indica el número de iteraciones que realizaremos en el entrenamiento. La estimación de estos parámetros se tiene que hacer por ensayo-error, probando con diferentes valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZg4vqexfsEs",
        "outputId": "e6722487-88a9-4b51-eab8-46e60cf83f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 38s 5ms/step - loss: 0.4596 - accuracy: 0.7943\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.4217 - accuracy: 0.8185\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.4074 - accuracy: 0.8317\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3958 - accuracy: 0.8390\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3875 - accuracy: 0.8378\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3833 - accuracy: 0.8395\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3770 - accuracy: 0.8422\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3708 - accuracy: 0.8429\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3649 - accuracy: 0.8505\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3601 - accuracy: 0.8522\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3564 - accuracy: 0.8555\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3542 - accuracy: 0.8536\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3519 - accuracy: 0.8568\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3499 - accuracy: 0.8546\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3493 - accuracy: 0.8572\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3479 - accuracy: 0.8551\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3477 - accuracy: 0.8585\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3458 - accuracy: 0.8585\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3460 - accuracy: 0.8581\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3449 - accuracy: 0.8581\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3441 - accuracy: 0.8561\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3429 - accuracy: 0.8590\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3440 - accuracy: 0.8596\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3432 - accuracy: 0.8579\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3429 - accuracy: 0.8584\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3429 - accuracy: 0.8595\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3421 - accuracy: 0.8589\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3425 - accuracy: 0.8599\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3414 - accuracy: 0.8614\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3403 - accuracy: 0.8605\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3406 - accuracy: 0.8575\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3419 - accuracy: 0.8587\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3407 - accuracy: 0.8576\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3414 - accuracy: 0.8581\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3400 - accuracy: 0.8597\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3401 - accuracy: 0.8594\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3402 - accuracy: 0.8599\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3391 - accuracy: 0.8593\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3390 - accuracy: 0.8620\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3382 - accuracy: 0.8606\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3388 - accuracy: 0.8584\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3381 - accuracy: 0.8593\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3394 - accuracy: 0.8595\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3387 - accuracy: 0.8602\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3377 - accuracy: 0.8586\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3389 - accuracy: 0.8585\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3382 - accuracy: 0.8601\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3382 - accuracy: 0.8620\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3373 - accuracy: 0.8602\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3385 - accuracy: 0.8621\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3386 - accuracy: 0.8602\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3375 - accuracy: 0.8606\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3374 - accuracy: 0.8590\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3369 - accuracy: 0.8608\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3369 - accuracy: 0.8585\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3376 - accuracy: 0.8620\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3383 - accuracy: 0.8586\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3365 - accuracy: 0.8599\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3375 - accuracy: 0.8618\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3366 - accuracy: 0.8583\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3377 - accuracy: 0.8599\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3367 - accuracy: 0.8606\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3370 - accuracy: 0.8605\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3364 - accuracy: 0.8608\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3380 - accuracy: 0.8594\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 35s 4ms/step - loss: 0.3369 - accuracy: 0.8619\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3370 - accuracy: 0.8606\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3364 - accuracy: 0.8580\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3368 - accuracy: 0.8581\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3368 - accuracy: 0.8612\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3359 - accuracy: 0.8606\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3364 - accuracy: 0.8624\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3360 - accuracy: 0.8627\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3354 - accuracy: 0.8610\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3365 - accuracy: 0.8589\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3358 - accuracy: 0.8597\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3362 - accuracy: 0.8625\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3348 - accuracy: 0.8622\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3348 - accuracy: 0.8596\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3352 - accuracy: 0.8622\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3356 - accuracy: 0.8620\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3361 - accuracy: 0.8604\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3364 - accuracy: 0.8597\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3357 - accuracy: 0.8601\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3354 - accuracy: 0.8601\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3353 - accuracy: 0.8633\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3357 - accuracy: 0.8591\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3360 - accuracy: 0.8605\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3359 - accuracy: 0.8622\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 30s 4ms/step - loss: 0.3351 - accuracy: 0.8614\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 35s 4ms/step - loss: 0.3348 - accuracy: 0.8622\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3356 - accuracy: 0.8606\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3359 - accuracy: 0.8601\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3345 - accuracy: 0.8590\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3346 - accuracy: 0.8602\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3363 - accuracy: 0.8593\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3361 - accuracy: 0.8599\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3360 - accuracy: 0.8581\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3347 - accuracy: 0.8615\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3356 - accuracy: 0.8596\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2505247ccd0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asYS7YpLfsEt"
      },
      "source": [
        "##### Anotación: El modelo alcanza casi el máximo rendimiento a las 25 iteraciones más o menos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWh_H2S1fsEu"
      },
      "source": [
        "Para realizar la predicción sobre nuestro conjunto de test lo haremos mediante la siguiente expresión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRYvOMYBfsEv",
        "outputId": "2c7b5095-3aad-4345-8ed3-49361342097f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09PyyzQLfsEw"
      },
      "outputs": [],
      "source": [
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3qUalERfsEw"
      },
      "source": [
        "La predicción nos proporcionará la probabilidad de pertenecer a un grupo u otro, de tal manera que aquellos valores mayores que 0.5 serán 1 y el resto 0.\n",
        "\n",
        "Creamos una matriz de confusión y vemos los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV8HeKuBfsEy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZRXCRiMfsEy",
        "outputId": "61fcec30-3019-4a2d-d914-082673c3a87f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1522,   86],\n",
              "       [ 185,  207]], dtype=int64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk_zwcBSfsE0",
        "outputId": "19cc34e1-2720-4870-8d6a-99896df25cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92      1608\n",
            "           1       0.71      0.53      0.60       392\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.80      0.74      0.76      2000\n",
            "weighted avg       0.86      0.86      0.86      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sklearn.metrics as metrics\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "523iokd8fsE1"
      },
      "source": [
        "### Pruebas con diferentes parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnVbCvelfsE2",
        "outputId": "38682ca9-9521-46ad-be77-f639d54d257e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 4ms/step\n",
            "63/63 [==============================] - 1s 4ms/step\n",
            "63/63 [==============================] - 0s 4ms/step\n",
            "63/63 [==============================] - 0s 4ms/step\n",
            "   Número de capas ocultas  Unidades ocultas por capa Tipo de capas  \\\n",
            "0                        2                          6         Dense   \n",
            "1                        2                         12         Dense   \n",
            "2                        2                          6         Dense   \n",
            "3                        2                         12         Dense   \n",
            "\n",
            "   Iteraciones (Épocas)  Batch size Función de activación  Precisión  \\\n",
            "0                    10           1                  ReLU   0.741803   \n",
            "1                    10           1                  ReLU   0.750000   \n",
            "2                    25           1                  ReLU   0.706107   \n",
            "3                    25           1                  ReLU   0.789474   \n",
            "\n",
            "         F1    Recall  Coeficiente kappa  \n",
            "0  0.569182  0.461735           0.492923  \n",
            "1  0.569620  0.459184           0.494349  \n",
            "2  0.565749  0.471939           0.484850  \n",
            "3  0.549085  0.420918           0.477914  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "epocas = [10, 25]\n",
        "neuronas = [6, 12]\n",
        "df = pd.DataFrame(columns=[])\n",
        "for i in range(len(epocas)):\n",
        "    for j in range(len(neuronas)):\n",
        "        classifier_2 = Sequential()\n",
        "        classifier_2.add(Dense(neuronas[j], activation = 'relu', input_shape = (10,)))\n",
        "        classifier_2.add(Dense(neuronas[j], activation = 'relu'))\n",
        "        classifier_2.add(Dense(neuronas[j], activation = 'relu'))\n",
        "        classifier_2.add(Dense(1, activation = 'sigmoid'))\n",
        "        classifier_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        classifier_2.fit(X_train, y_train, epochs=epocas[i], batch_size=1, verbose=0)\n",
        "        y_pred = classifier_2.predict(X_test)\n",
        "        y_pred = (y_pred > 0.5)\n",
        "\n",
        "\n",
        "        datos = {\n",
        "        'Número de capas ocultas': 2,\n",
        "        'Unidades ocultas por capa': neuronas[j],\n",
        "        'Tipo de capas': 'Dense',\n",
        "        'Iteraciones (Épocas)': epocas[i],\n",
        "        'Batch size': 1,\n",
        "        'Función de activación': 'ReLU',\n",
        "        'Precisión': precision_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test,y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'Coeficiente kappa': cohen_kappa_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "        datos = pd.DataFrame([datos])\n",
        "        df = pd.concat([df, datos], ignore_index=True)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvdPzQLIfsE4"
      },
      "source": [
        "De lo aprendido en los guiones anteriores, se ha incrementado el número de capas ocultas (2) así como el número de neuronas (12). Como función de activación se ha mantenido la ReLU y se han utilizado 2 valores distintos para las iteraciones (Épocas) para poder ver la diferencia en el rendimiento. El resultado es que el modelo con mayor número de neuronas y cantidad de iteraciones ha obtenido el mejor rendimiento de todos, obteniendo una precisión del 80% prácticamente pese a tener la peor recuperación, esto indica que este modelo se ha sobreajustado un poco. Se deberían hacer más pruebas para encontrar un equilibrio entre recuperación y precisión y que así el modelo fuese efectivo al usar nuevos conjuntos de datos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}